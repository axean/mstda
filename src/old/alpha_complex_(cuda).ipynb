{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261ce3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CUDA device 0 'b'NVIDIA GeForce GTX 1070 Ti''>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda,float32\n",
    "import scipy.spatial as spatial\n",
    "import numpy as np\n",
    "#from rich import print\n",
    "import matplotlib.pyplot as plt\n",
    "from more_itertools import powerset\n",
    "print(cuda.current_context().device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee4d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 3 0]]\n",
      "[[-1 -1 -1  2]\n",
      " [-1 -1  0  3]\n",
      " [-1  1  2  3]\n",
      " [-1 -1  1  2]\n",
      " [ 0  1  2  3]\n",
      " [-1 -1 -1  0]\n",
      " [-1 -1 -1  3]\n",
      " [-1 -1  1  3]\n",
      " [-1 -1  0  1]\n",
      " [-1 -1  2  3]\n",
      " [-1  0  1  2]\n",
      " [-1 -1 -1  1]\n",
      " [-1  0  1  3]\n",
      " [-1 -1  0  2]\n",
      " [-1  0  2  3]]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(4,3)\n",
    "dimension = X.shape[1]\n",
    "tri = spatial.Delaunay(X)\n",
    "delaunay_complex = [ powerset(face) for face in tri.simplices ]\n",
    "delaunay_complex = list(set([\n",
    "    tuple(sorted(\n",
    "        list(item) + [-1 for _ in range(len(item), dimension + 1)]\n",
    "    )) for sublist in delaunay_complex for item in sublist\n",
    "]) - {(-1,-1,-1,-1)})\n",
    "filtration = np.zeros((len(delaunay_complex)))\n",
    "filtration[:] = -1\n",
    "delaunay_complex = np.asarray(delaunay_complex)\n",
    "tri = np.asarray(tri.simplices)\n",
    "print(tri)\n",
    "print(delaunay_complex)\n",
    "print(filtration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b93e47",
   "metadata": {},
   "source": [
    "# Declare kernel function\n",
    "https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-declaration\n",
    "\n",
    "When running a kernel, the kernel functionâ€™s code is executed by every thread once. It therefore has to know which thread it is in, in order to know which array element(s) it is responsible for (complex algorithms may define more complex responsibilities, but the underlying principle is the same).\n",
    "\n",
    "![](https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/grid-of-thread-blocks.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c45ee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cayley_menger_shape (1, 5, 5)\n",
      "blockspergrid  1\n"
     ]
    }
   ],
   "source": [
    "threadsperblock = 32\n",
    "cayley_menger_shape = ( tri.shape[0], dimension + 2, dimension + 2)\n",
    "subfaces_shape = (tri.shape[0], 2**(dimension+1) - (dimension + 2))\n",
    "print('cayley_menger_shape', cayley_menger_shape)\n",
    "blockspergrid = (tri.size + (threadsperblock - 1)) // threadsperblock\n",
    "print('blockspergrid ', blockspergrid)\n",
    "\n",
    "@cuda.jit\n",
    "def alpha_complex(\n",
    "    tri,             # Delaunay triangulation (d-simplices only). Every thread gets a d-simplex.\n",
    "    delaunay_asc,    # Delaunay complex (abstract simplical complex). Threads use this to lookup where to store result.\n",
    "    distance_matrix, # Pre-computed distance matrix.\n",
    "    filtration       # Output array, the filtration values in the order of delaunay_asc.\n",
    "):\n",
    "    cayley_menger = cuda.shared.array(\n",
    "        shape = cayley_menger_shape,\n",
    "        dtype = float32\n",
    "    )\n",
    "    \n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    if idx < tri.shape[0]:\n",
    "        # prepare Cayley Menger matrix\n",
    "        cayley_menger[idx,:,1:] = 1\n",
    "        cayley_menger[idx,1:,:] = 1\n",
    "        cayley_menger[idx,0,0]  = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674091c5",
   "metadata": {},
   "source": [
    "# Invoke kernel function\n",
    "https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation\n",
    "\n",
    "We need to compile the function first, which is done by invoking it for small valid input.\n",
    "There is a limit to the number of threads per block, since all threads of a block are expected to reside on the same processor core and must share the limited memory resources of that core. On current GPUs, a thread block may contain up to 1024 threads.\n",
    "https://docs.nvidia.com/cuda/cuda-c-programming-guide/#thread-hierarchy\n",
    "\n",
    "![](https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/memory-hierarchy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7a3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = spatial.distance_matrix(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df3410e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axean/anaconda3/envs/az1/lib/python3.9/site-packages/numba/cuda/compiler.py:865: NumbaPerformanceWarning: \u001b[1mGrid size (1) < 2 * SM count (38) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home/axean/anaconda3/envs/az1/lib/python3.9/site-packages/numba/cuda/cudadrv/devicearray.py:790: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "alpha_complex[blockspergrid, threadsperblock](tri, delaunay_complex, distance_matrix, filtration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3: Topological Data Analysis",
   "language": "python",
   "name": "az1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
